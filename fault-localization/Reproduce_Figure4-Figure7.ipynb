{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab Setup  \n",
    "> Make sure you configure notebook with GPU: Click Edit->notebook settings->hardware accelerator->GPU\n",
    "\n",
    "> Uncomment the following cell after opening in Google colab. (Do not uncomment it in local setup.)  \n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/SEED-VT/FedDebug/blob/main/fault-localization/Reproduce_Figure4-Figure7.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-lightning\n",
    "# !pip install diskcache\n",
    "# !pip install dotmap\n",
    "# !pip install torch torchvision torchaudio\n",
    "# !pip install matplotlib\n",
    "# !git clone https://github.com/SEED-VT/FedDebug.git\n",
    "# # appending the path\n",
    "# import sys\n",
    "# sys.path.append(\"FedDebug/fault-localization/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripiton\n",
    "\n",
    "- The code is simulating the presence of a faulty client in a federated learning setting by introducing noise to the model updates from a faulty client. The `noise_rate` variable is used to control the amount of noise added.\n",
    "\n",
    "- For each noise level, the code performs FL training, aggregation to update the global model, and testing of the global model's accuracy. \n",
    "\n",
    "- The code also runs `FedDebug's fault localization algorithm` to identify potentially faulty clients and evaluate the accuracy of the fault localization. \n",
    "\n",
    "- The results of the simulation are stored in a list, and the `global model accuracy` and `fault localization accuracy` are plotted against the `noise rate`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gulzar/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Global seed set to 786\n",
      "Global seed set to 786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\n",
      "  ***Simulating FL setup iid_resnet18_cifar10_clients_10_faulty_[0]_bsize_512_epochs_10_lr_0.001 ***\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Spliting Datasets 50000 into parts:[5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m args\u001b[39m.\u001b[39mnoise_rate \u001b[39m=\u001b[39m noise_rate  \u001b[39m# noise rate 0 to 1 \u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39m# FL training\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m c2ms, exp2info \u001b[39m=\u001b[39m trainFLMain(args)\n\u001b[1;32m     78\u001b[0m client2models \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval() \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m c2ms\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     80\u001b[0m gm \u001b[39m=\u001b[39m  aggToUpdateGlobalModel(clients_models\u001b[39m=\u001b[39mclient2models)\n",
      "File \u001b[0;32m~/Github/FedDebug/fault-localization/utils/FLSimulation.py:117\u001b[0m, in \u001b[0;36mtrainFLMain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mfor\u001b[39;00m faulty_id \u001b[39min\u001b[39;00m faulty_clients_ids:\n\u001b[1;32m    115\u001b[0m     k \u001b[39m=\u001b[39m checkpoint_dir \u001b[39m+\u001b[39m \\\n\u001b[1;32m    116\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m/faulty_client_\u001b[39m\u001b[39m{\u001b[39;00mfaulty_id\u001b[39m}\u001b[39;00m\u001b[39m_noise_rate_\u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m.\u001b[39mnoise_rate\u001b[39m}\u001b[39;00m\u001b[39m_classes.ckpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 117\u001b[0m     faultyclients2datasets[k] \u001b[39m=\u001b[39m NoisyDataset(copy\u001b[39m.\u001b[39;49mdeepcopy(\n\u001b[1;32m    118\u001b[0m         clientsdatasets[faulty_id]), num_classes\u001b[39m=\u001b[39mnum_classes, noise_rate\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mnoise_rate)\n\u001b[1;32m    119\u001b[0m     stringID2intID[k] \u001b[39m=\u001b[39m faulty_id\n\u001b[1;32m    121\u001b[0m normalclients2datasets \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m copier \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39m__deepcopy__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     y \u001b[39m=\u001b[39m copier(memo)\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     reductor \u001b[39m=\u001b[39m dispatch_table\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from dotmap import DotMap\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch.nn.init import kaiming_uniform_ \n",
    "from utils.faulty_client_localization.FaultyClientLocalization import FaultyClientLocalization\n",
    "from utils.faulty_client_localization.InferenceGuidedInputs import InferenceGuidedInputs\n",
    "from utils.FLSimulation import trainFLMain\n",
    "from utils.fl_datasets import initializeTrainAndValidationDataset\n",
    "from utils.util import aggToUpdateGlobalModel\n",
    "from utils.util import testAccModel\n",
    "\n",
    "\n",
    "\n",
    "logging.basicConfig(filename='example.log', level=logging.ERROR)\n",
    "logger = logging.getLogger(\"pytorch_lightning\")\n",
    "seed_everything(786)\n",
    "\n",
    "\n",
    "\n",
    "def evaluateFaultLocalization(predicted_faulty_clients_on_each_input, true_faulty_clients):\n",
    "    true_faulty_clients = set(true_faulty_clients)\n",
    "    detection_acc = 0\n",
    "    for pred_faulty_clients in predicted_faulty_clients_on_each_input:\n",
    "        print(f\"+++ Faulty Clients {pred_faulty_clients}\")\n",
    "        correct_localize_faults = len(\n",
    "            true_faulty_clients.intersection(pred_faulty_clients))\n",
    "        acc = (correct_localize_faults/len(true_faulty_clients))*100\n",
    "        detection_acc += acc\n",
    "    fault_localization_acc = detection_acc / \\\n",
    "        len(predicted_faulty_clients_on_each_input)\n",
    "    return fault_localization_acc\n",
    "\n",
    "\n",
    "def runFaultyClientLocalization(client2models, exp2info, num_bugs, random_generator=kaiming_uniform_, apply_transform=True, k_gen_inputs=10, na_threshold=0.003, use_gpu=True):\n",
    "    print(\">  Running FaultyClientLocalization ..\")\n",
    "    input_shape = list(exp2info['data_config']['single_input_shape'])\n",
    "    generate_inputs = InferenceGuidedInputs(client2models, input_shape, randomGenerator=random_generator, apply_transform=apply_transform,\n",
    "                                            dname=exp2info['data_config']['name'], min_nclients_same_pred=5, k_gen_inputs=k_gen_inputs)\n",
    "    selected_inputs, input_gen_time = generate_inputs.getInputs()\n",
    "\n",
    "    start = time.time()\n",
    "    faultyclientlocalization = FaultyClientLocalization(\n",
    "        client2models, selected_inputs, use_gpu=use_gpu)\n",
    "\n",
    "    potential_benign_clients_for_each_input = faultyclientlocalization.runFaultLocalization(\n",
    "        na_threshold, num_bugs=num_bugs)\n",
    "    fault_localization_time = time.time()-start\n",
    "    return potential_benign_clients_for_each_input, input_gen_time, fault_localization_time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====== Simulation ===== \n",
    "\n",
    "args = DotMap()\n",
    "args.lr = 0.001\n",
    "args.weight_decay = 0.0001\n",
    "args.batch_size = 512\n",
    "\n",
    "nosie2results = []\n",
    "different_noise_levels = [0.1, 0.3, 0.5, 0.7, 0.9, 1]\n",
    "args.model = \"resnet18\" # [resnet18, resnet34, resnet50, densenet121, vgg16]\n",
    "args.epochs = 10  # range 10-25\n",
    "args.dataset = \"cifar10\" # ['cifar10', 'femnist']\n",
    "args.clients = 10 # keep under 30 clients and use Resnet18, Resnet34, or Densenet to evaluate on Colab \n",
    "args.faulty_clients_ids = \"0\" # can be multiple clients separated by comma e.g. \"0,1,2\"  but keep under args.clients clients and at max less than 7 \n",
    "args.sampling = \"iid\" # [iid, \"niid\"] \n",
    "\n",
    "_,test_data, _ =  initializeTrainAndValidationDataset(args.dataset, \".storage/datasets/\")\n",
    "\n",
    "for noise_rate in different_noise_levels:\n",
    "    args.noise_rate = noise_rate  # noise rate 0 to 1 \n",
    "    # FL training\n",
    "    c2ms, exp2info = trainFLMain(args)\n",
    "    client2models = {k: v.model.eval() for k, v in c2ms.items()}\n",
    "\n",
    "    gm =  aggToUpdateGlobalModel(clients_models=client2models)\n",
    "    test_acc = testAccModel(gm, test_data)\n",
    "\n",
    "    # Fault localazation\n",
    "    potential_faulty_clients, _, _ = runFaultyClientLocalization(\n",
    "        client2models=client2models, exp2info=exp2info, num_bugs=len(exp2info['faulty_clients_ids']))\n",
    "    fault_acc = evaluateFaultLocalization(\n",
    "        potential_faulty_clients, exp2info['faulty_clients_ids'])\n",
    "    print(f\"Fault Localization Acc: {fault_acc}\")\n",
    "\n",
    "    print(f\"Gloabl Model Test Acc: {test_acc}, Noise Rate: {noise_rate}, Fault Acc: {fault_acc}\")\n",
    "    nosie2results.append((noise_rate, test_acc, fault_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =different_noise_levels \n",
    "y1_test_acc = [y[1] for y in nosie2results]\n",
    "y2_fault_acc = [y[2] for y in nosie2results]\n",
    "fig, axes = plt.subplots(1, 2) \n",
    "axes[0].plot(x, y1_test_acc, 'g--o') \n",
    "axes[1].plot(x, y2_fault_acc, 'm--o')\n",
    "\n",
    "axes[0].set_xlabel('Noise Rate')\n",
    "axes[1].set_xlabel('Noise Rate')\n",
    "axes[0].set_ylabel('Global Model Accuracy (%)')\n",
    "axes[1].set_ylabel('Fault Localization Accuracy (%)')\n",
    "axes[0].set_title(\"Paper Figure 4 (a)\")\n",
    "axes[1].set_title(\"Paper Figure 7 (a)\")\n",
    "\n",
    "axes[0].set_ylim(0, 105)\n",
    "axes[1].set_ylim(0, 105)\n",
    "\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "90b2b3ffc921ecec285732ffefdcd2be049b62625871c2bd1061419cc3e1c031"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
